{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Scraping Startup Data from NIC (National Incubation Center) Hyderabad Sindh, Pakistan\n\n## Introduction\n\nThe National Incubation Center (NIC) Hyderabad is a hub for fostering innovation and entrepreneurship in Sindh, Pakistan. This notebook aims to scrape and compile data on startups from the NIC Hyderabad website. The objective is to gather information on the startups, including their names, descriptions, and links to their detailed profiles, which can be used for further analysis and research.\n\n## 1. Setup and Libraries\n\nIn this section, we will import the necessary libraries required for web scraping and data processing.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport requests\nfrom bs4 import BeautifulSoup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-24T12:06:37.641954Z","iopub.execute_input":"2024-06-24T12:06:37.643128Z","iopub.status.idle":"2024-06-24T12:06:37.648894Z","shell.execute_reply.started":"2024-06-24T12:06:37.643088Z","shell.execute_reply":"2024-06-24T12:06:37.647321Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## 3. Web Scraping\n### Base URL and Headers\nWe define the base URL for NIC Hyderabad cohorts and set headers to mimic a real browser.","metadata":{}},{"cell_type":"code","source":"# Base URL adding 1, 2, 3, end of will make the change the round/cohort\nurl = 'https://nichyderabad.com/about/cohort-'\n\n# Set headers to mimic a real browser\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:37.651284Z","iopub.execute_input":"2024-06-24T12:06:37.651784Z","iopub.status.idle":"2024-06-24T12:06:37.662596Z","shell.execute_reply.started":"2024-06-24T12:06:37.651688Z","shell.execute_reply":"2024-06-24T12:06:37.661207Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"## 3. Fetching Data from NIC Hyderabad\nWe fetch the web pages for each cohort and parse the HTML content.","metadata":{}},{"cell_type":"code","source":"# to temprary save all the responces\nresponses = {'cohorts':[], 'sope':[]}\n\n# itrating ovwer all the cohorts page\nfor i in range(1, 5): # till this date 24/06/2024 we only have four cohorts\n  # fatching the page of the iterate index\n  response= requests.get(url+f'{i}', headers=headers)\n  # only if the request is seccefull\n  if response.status_code == 200:\n    # save the cohort to the responses\n    responses['cohorts'].append(i)\n    # turning the responce to sope\n    soup = BeautifulSoup(response.content, 'html.parser')\n    # saving that sope in responses\n    responses['sope'].append(soup)\n  else: print(response.status_code, 'for searching cohort', i)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:37.664618Z","iopub.execute_input":"2024-06-24T12:06:37.665091Z","iopub.status.idle":"2024-06-24T12:06:41.609381Z","shell.execute_reply.started":"2024-06-24T12:06:37.665055Z","shell.execute_reply":"2024-06-24T12:06:41.607943Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"### Extracting Data for Each Cohort\nWe extract the relevant data (company names, URL of the each startup's profile page, and cohort session) from each cohort's page.\n#### Cohort 1","metadata":{}},{"cell_type":"code","source":"# for cohort 1\nsoup_cohort1 = responses['sope'][0]","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:41.614436Z","iopub.execute_input":"2024-06-24T12:06:41.615024Z","iopub.status.idle":"2024-06-24T12:06:41.621583Z","shell.execute_reply.started":"2024-06-24T12:06:41.614982Z","shell.execute_reply":"2024-06-24T12:06:41.620344Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# selecting all \"div\" eiliments with class content-container\ncontent_container = soup_cohort1.find_all('div', class_='content-container')\nprint('Total number of retrieve compony in cohort-1', len(content_container))","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:41.622902Z","iopub.execute_input":"2024-06-24T12:06:41.623265Z","iopub.status.idle":"2024-06-24T12:06:41.646324Z","shell.execute_reply.started":"2024-06-24T12:06:41.623236Z","shell.execute_reply":"2024-06-24T12:06:41.644853Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Total number of retrieve compony in cohort-1 20\n","output_type":"stream"}]},{"cell_type":"code","source":"NIC = {'company':[], 'NIC-URL':[], 'cohort':[]}\n\nfor i in content_container:\n  if i.find('p').find_all('a') != []:\n    company_url=i.find('p').find_all('a')[0].get('href')\n    NIC[\"company\"].append(company_url.split('/')[-2])\n    NIC[\"NIC-URL\"].append(company_url)\n\n# adding 1 to each cohort equel to the number of the other observation\nNIC[\"cohort\"]=[1]*len(NIC[\"company\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:41.649137Z","iopub.execute_input":"2024-06-24T12:06:41.649648Z","iopub.status.idle":"2024-06-24T12:06:41.662781Z","shell.execute_reply.started":"2024-06-24T12:06:41.649615Z","shell.execute_reply":"2024-06-24T12:06:41.661366Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"NIC_df = pd.DataFrame(NIC)\nNIC_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:41.664479Z","iopub.execute_input":"2024-06-24T12:06:41.664871Z","iopub.status.idle":"2024-06-24T12:06:41.687552Z","shell.execute_reply.started":"2024-06-24T12:06:41.664835Z","shell.execute_reply":"2024-06-24T12:06:41.686242Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"                  company                                            NIC-URL  \\\n0                  emplai    https://nichyderabad.com/about/cohort-1/emplai/   \n1  agridunya-technologies  https://nichyderabad.com/about/cohort-1/agridu...   \n2     seevitals-solutions  https://nichyderabad.com/about/cohort-1/seevit...   \n3                  monitr    https://nichyderabad.com/about/cohort-1/monitr/   \n4             upni-market  https://nichyderabad.com/about/cohort-1/upni-m...   \n\n   cohort  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>company</th>\n      <th>NIC-URL</th>\n      <th>cohort</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>emplai</td>\n      <td>https://nichyderabad.com/about/cohort-1/emplai/</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agridunya-technologies</td>\n      <td>https://nichyderabad.com/about/cohort-1/agridu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>seevitals-solutions</td>\n      <td>https://nichyderabad.com/about/cohort-1/seevit...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>monitr</td>\n      <td>https://nichyderabad.com/about/cohort-1/monitr/</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>upni-market</td>\n      <td>https://nichyderabad.com/about/cohort-1/upni-m...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Fetching the all the other cohorts","metadata":{}},{"cell_type":"code","source":"total_page = len(responses['sope'])\n# cohort 2 and on\nfor i in range(1, total_page):\n  sope_cohort = responses['sope'][i]\n  # find all \"a\" tages with heading-link class ans store in list\n  a_tags = sope_cohort.find_all('a', class_='heading-link')\n  print(f'Total number of retrieve compony in cohort-{i+1} are', len(a_tags))\n  for j in a_tags:\n    # add the company, url, and cohort 2 to the NIC_df\n    NIC_df.loc[len(NIC_df)] = [j.get('href').split('/')[-2], j.get('href'), 2]","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:41.688951Z","iopub.execute_input":"2024-06-24T12:06:41.689330Z","iopub.status.idle":"2024-06-24T12:06:41.785005Z","shell.execute_reply.started":"2024-06-24T12:06:41.689298Z","shell.execute_reply":"2024-06-24T12:06:41.783581Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Total number of retrieve compony in cohort-2 are 28\nTotal number of retrieve compony in cohort-3 are 20\nTotal number of retrieve compony in cohort-4 are 14\n","output_type":"stream"}]},{"cell_type":"code","source":"NIC_df.drop_duplicates(inplace=True)\nNIC_df[NIC_df['company'].duplicated(keep=False)]","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:41.786420Z","iopub.execute_input":"2024-06-24T12:06:41.786788Z","iopub.status.idle":"2024-06-24T12:06:41.806302Z","shell.execute_reply.started":"2024-06-24T12:06:41.786757Z","shell.execute_reply":"2024-06-24T12:06:41.804956Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"             company                                            NIC-URL  \\\n23  nichyderabad.com  https://nichyderabad.com/?page_id=9974&preview...   \n30  nichyderabad.com  https://nichyderabad.com/?page_id=9957&preview...   \n31  nichyderabad.com  https://nichyderabad.com/?page_id=9976&preview...   \n35  nichyderabad.com  https://nichyderabad.com/?page_id=9913&preview...   \n75  nichyderabad.com  https://nichyderabad.com/?page_id=10985&previe...   \n79  nichyderabad.com  https://nichyderabad.com/?page_id=10953&previe...   \n\n    cohort  \n23       2  \n30       2  \n31       2  \n35       2  \n75       2  \n79       2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>company</th>\n      <th>NIC-URL</th>\n      <th>cohort</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>nichyderabad.com</td>\n      <td>https://nichyderabad.com/?page_id=9974&amp;preview...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>nichyderabad.com</td>\n      <td>https://nichyderabad.com/?page_id=9957&amp;preview...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>nichyderabad.com</td>\n      <td>https://nichyderabad.com/?page_id=9976&amp;preview...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>nichyderabad.com</td>\n      <td>https://nichyderabad.com/?page_id=9913&amp;preview...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>nichyderabad.com</td>\n      <td>https://nichyderabad.com/?page_id=10985&amp;previe...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>nichyderabad.com</td>\n      <td>https://nichyderabad.com/?page_id=10953&amp;previe...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"*Note: Now that we have the like for each page of the startup on NIC website, we will start to fatch the data from thos page*","metadata":{}},{"cell_type":"code","source":"def get_soup(link_:str) -> BeautifulSoup:\n    response = requests.get(link_, headers=headers)\n    if response.status_code == 200:\n        soup = BeautifulSoup(response.content, 'html.parser')\n        return soup\n    else:\n        print(response.status_code, 'for', link)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:41.807646Z","iopub.execute_input":"2024-06-24T12:06:41.808111Z","iopub.status.idle":"2024-06-24T12:06:41.821022Z","shell.execute_reply.started":"2024-06-24T12:06:41.808068Z","shell.execute_reply":"2024-06-24T12:06:41.819240Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"import re\n\nfor i in NIC_df['NIC-URL'].index:\n  soup = get_soup(NIC_df['NIC-URL'][i])\n  table_div = soup.find('div', class_= re.compile(r'fusion-text fusion-text-2.*'))\n  # print(i, NIC_df['NIC-URL'][i])\n  table = table_div.find('table')\n\n  # Iterate over each row in the table\n  for row in table.find_all('tr'):\n      # Extract columns from each row\n      columns = row.find_all('td')\n      # Get the text content of each column and strip any extra whitespace\n      columns = [col.get_text(strip=True) for col in columns]\n      # add this info to the NIC_df where only have three columns [company\tNIC-URL\tcohort]\n      if len(columns) >= 2:\n        NIC_df.loc[i, columns[0]] = columns[1]","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:06:41.823171Z","iopub.execute_input":"2024-06-24T12:06:41.823541Z","iopub.status.idle":"2024-06-24T12:07:50.113479Z","shell.execute_reply.started":"2024-06-24T12:06:41.823507Z","shell.execute_reply":"2024-06-24T12:07:50.112196Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# find rows having nan\nprint(NIC_df[NIC_df.isna().any(axis=1)])\nNIC_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:07:50.116489Z","iopub.execute_input":"2024-06-24T12:07:50.116865Z","iopub.status.idle":"2024-06-24T12:07:50.138127Z","shell.execute_reply.started":"2024-06-24T12:07:50.116833Z","shell.execute_reply":"2024-06-24T12:07:50.136853Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Empty DataFrame\nColumns: [company, NIC-URL, cohort, STARTUP, STARTUP STAGE, DOMAIN, WEBSITE, FOUNDER, CONTACT, EMAIL]\nIndex: []\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"                  company                                            NIC-URL  \\\n0                  emplai    https://nichyderabad.com/about/cohort-1/emplai/   \n1  agridunya-technologies  https://nichyderabad.com/about/cohort-1/agridu...   \n2     seevitals-solutions  https://nichyderabad.com/about/cohort-1/seevit...   \n3                  monitr    https://nichyderabad.com/about/cohort-1/monitr/   \n4             upni-market  https://nichyderabad.com/about/cohort-1/upni-m...   \n\n   cohort                 STARTUP STARTUP STAGE          DOMAIN  \\\n0       1                  EmplAi    Accelerate  HR, Attendance   \n1       1  AgriDunya Technologies    Accelerate          AgTech   \n2       1               SeeVitals    Accelerate     Health Tech   \n3       1                  Monitr    Accelerate   Ed-Tech, SAAS   \n4       1             Upni Market    Accelerate      E-commerce   \n\n                      WEBSITE                            FOUNDER  \\\n0       http://www.emplai.ai/  Aftab Ahmed Saraz (CEO & Founder)   \n1  https://www.agridunya.com/                      Rahul Dembani   \n2   http://www.seevitals.com/                  Dr. Nimra Qureshi   \n3             www.monitr.site             Daeyan Hafeez Siddiqui   \n4          www.Upnimarket.com                        Ahsan Zahid   \n\n           CONTACT                    EMAIL  \n0                –                        –  \n1  +92 330 0792000    support@agridunya.com  \n2   +92 3451591251       info@SeeVitals.com  \n3     0345 3531573  daeyansidi826@gmail.com  \n4  +92 322 0232991      info@upnimarket.com  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>company</th>\n      <th>NIC-URL</th>\n      <th>cohort</th>\n      <th>STARTUP</th>\n      <th>STARTUP STAGE</th>\n      <th>DOMAIN</th>\n      <th>WEBSITE</th>\n      <th>FOUNDER</th>\n      <th>CONTACT</th>\n      <th>EMAIL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>emplai</td>\n      <td>https://nichyderabad.com/about/cohort-1/emplai/</td>\n      <td>1</td>\n      <td>EmplAi</td>\n      <td>Accelerate</td>\n      <td>HR, Attendance</td>\n      <td>http://www.emplai.ai/</td>\n      <td>Aftab Ahmed Saraz (CEO &amp; Founder)</td>\n      <td>–</td>\n      <td>–</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agridunya-technologies</td>\n      <td>https://nichyderabad.com/about/cohort-1/agridu...</td>\n      <td>1</td>\n      <td>AgriDunya Technologies</td>\n      <td>Accelerate</td>\n      <td>AgTech</td>\n      <td>https://www.agridunya.com/</td>\n      <td>Rahul Dembani</td>\n      <td>+92 330 0792000</td>\n      <td>support@agridunya.com</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>seevitals-solutions</td>\n      <td>https://nichyderabad.com/about/cohort-1/seevit...</td>\n      <td>1</td>\n      <td>SeeVitals</td>\n      <td>Accelerate</td>\n      <td>Health Tech</td>\n      <td>http://www.seevitals.com/</td>\n      <td>Dr. Nimra Qureshi</td>\n      <td>+92 3451591251</td>\n      <td>info@SeeVitals.com</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>monitr</td>\n      <td>https://nichyderabad.com/about/cohort-1/monitr/</td>\n      <td>1</td>\n      <td>Monitr</td>\n      <td>Accelerate</td>\n      <td>Ed-Tech, SAAS</td>\n      <td>www.monitr.site</td>\n      <td>Daeyan Hafeez Siddiqui</td>\n      <td>0345 3531573</td>\n      <td>daeyansidi826@gmail.com</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>upni-market</td>\n      <td>https://nichyderabad.com/about/cohort-1/upni-m...</td>\n      <td>1</td>\n      <td>Upni Market</td>\n      <td>Accelerate</td>\n      <td>E-commerce</td>\n      <td>www.Upnimarket.com</td>\n      <td>Ahsan Zahid</td>\n      <td>+92 322 0232991</td>\n      <td>info@upnimarket.com</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 4. Saving the Data\nFinally, we save the collected and processed data to a CSV file for future analysis.","metadata":{}},{"cell_type":"code","source":"NIC_df.to_csv('NIC_startups-data.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:07:50.139634Z","iopub.execute_input":"2024-06-24T12:07:50.140094Z","iopub.status.idle":"2024-06-24T12:07:50.152899Z","shell.execute_reply.started":"2024-06-24T12:07:50.140051Z","shell.execute_reply":"2024-06-24T12:07:50.151504Z"},"trusted":true},"execution_count":67,"outputs":[]}]}